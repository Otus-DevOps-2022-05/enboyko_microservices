# enboyko_microservices
enboyko microservices repository

---
# HOMEWORK #12 and #13 (2in1):

<details>
  <summary>Описание</summary>

1. Создал репозиторий **docker-2**
2. Установил **docker** и **docker-tools**
3. Попрактиковал и изучил базовые команды **docker**
4. Устновил и настроил **docker-machine**
5. Создал новый инстанс в **YC** из стандартного образа в **image-family** **ubuntu-1804-lts**
6. В вышеуказанном инстансе создал *docker-host* с помощью **docker-machine**
7. Создал структуру репозитория **docker-monolith**, из **Dockerfile** собрал образ, на основании которого затем запустил контейнер и проверил работу приложения.
8. Аутентифицировался на **docker-hub** (ранее был зарегистрирован) и попрактиковался в работе с ним.
9. Удалил инстанс в Yandex Cloud

#### Задание со ⭐

1. В **docker-1.log** сравнил вывод команд:
    `docker inspect <u_container_id>`
    и
    `docker inspect <u_image_id>`
</details>

---
# HOMEWORK #14:

<details>
  <summary>Описание</summary>

1. Установил и применял в работе **linter** - **hadolint**
2. Разбил приложение на несколько компонентов - создал новую структуру микросервисного приложения.
Для каждого сервиса - **post-py**, **comment** и **ui** - создал свой **Dockerfile**. Собрал, запустил и проверил приложение.
3. Оптимизировал образ для сервиса **ui** - таким образом, уменьшил его размер. Пересобрал, перезапустил и проверил приложение.
4. Создал Docker volume, подключил его к контейнеру с **MongoDB**. Пересобрал, перезапустил и проверил приложение.
</details>

---
# HOMEWORK #15:

<details>
  <summary>Описание</summary>

### 1. Работа с сетями в Docker
1. Разобрался с работой сетей в **Docker** - с такими **network driver**'ами, как **none**, **host** и **bridge**
В частности, создал сети **back_net** и **front_net** - две **bridge**-сети. При этом сервис ui не имел напрямую доступа к базе данных.
2. Изучил, как выглядит сетевой стек Linux при топологии **bridge network driver**
Во всех рассмотренных случаях запустил приложение и проверил его работу.

### 2. Использование docker-compose
1. Установил **docker-compose** на локальную машину.
2. Собрал образы приложения **reddit** с помощью **docker-compose**
3. Запустил приложение **reddit** с помощью **docker-compose**
4. Оптимизировал конфигурацию **docker-compose**, добавив интерполяцию (подстановку) переменных окружения в **docker-compose.yml**. При этом сами переменные окружения инициализировал и объявил в файле для параметризации **.env**

#### Ответ на вопросы из задания в методическом указании:
1. Базовое имя проекта формируется из имени корневого каталога для файла **docker-compose.yml** ; в нашем случае, это - **src**.
2. Имя проекта можно задать:
- с помощью команды `docker-compose -p [имя_проекта] up -d`
- с помощью инициализации и объявления переменной окружения **COMPOSE_PROJECT_NAME** в файле параметризации типа **.env***
</details>

---
# HOMEWORK #16:

<details>
  <summary>Описание</summary>

### 1. Подготовил инсталляцию Gitlab CI
1. Создал в **Yandex.Cloud** новую виртуальную машину (инстанс) с помощью **Yandex.Cloud CLI**.
2. В вышеуказанном инстансе создал *docker-host* с помощью **docker-machine**.
3. На инстансе создал директории под **data volumes**.
4. В директории **/srv/gitlab** создал файл **docker-compose.yml**.
5. Запустил контейнер и проверил корректность отображения **GitLab** в браузере по адресу инстанса в **Yandex.Cloud**.
6. На стартовой странице указал логин и пароль для административного аккаунта (**root**).
7. Отключил регистрацию в **GitLab**.
8. Создал группу и проект.
9. Добавил удаленный репозиторий (в **GitLab**) в конфиг **Git**’а.

### 2. Описал для приложения этапы пайплайна
1. Определил пайплайн для **GitLab** в файле **.gitlab-ci.yml**.
2. Запушил изменения в удаленный репозиторий.
3. Проверил статус пайплайна - он находился в статусе **pending** (или **stuck**).
4. В настройках проекта получил токен для регистрации будущего раннера.
5. Добавил раннер.
6. Зарегистрировал раннер.
7. Проверил раннер - увидел его в настройках.
8. Проверил пайплайн - он запустился после добавления раннера.

### 3. Подготовил репозиторий с кодом приложения
1. Добавил исходный код **reddit** в репозиторий.
2. Создал файл **simpletest.rb** с тестами в директории **reddit**.
3. Добавил библиотеку **rack-test** для тестирования в файл **reddit/Gemfile**.
4. Запушил код в **GitLab** и убедился, что теперь **test_unit_job** гоняет тесты.

### 4. Определил окружения
1. Добавил окружения **dev**, **staging** и **production** в **.gitlab-ci.yml**.
2. Проверил наличие новых окружений.
3. Добавил в описание пайплайна директиву **only**, которая не позволит выкатить на **staging** и **production** код, не помеченный с помощью тэга в **git**.
4. Добавил задачу с динамическими окружениями в **.gitlab-ci.yml**.
5. Проверил создание динамических окружений.
</details>

---
# HOMEWORK #17:

<details>
  <summary>Описание</summary>

### 1. Prometheus: запуск, конфигурация, знакомство с Web UI
1. Создал в **Yandex.Cloud** новую виртуальную машину (инстанс) с помощью **Yandex.Cloud CLI**.
2. В вышеуказанном инстансе создал *docker-host* с помощью **docker-machine**.
3. Запустил **Prometheus** внутри **Docker-контейнера**: для начального знакомства с **Prometheus** воспользовался готовым образом с **DockerHub**.
4. В веб-интерфейсе **Prometheus** ознакомился и попрактиковался со строкой ввода выражений, **Targets**, вкладками **Console** и **Graph** и т.д.
5. Переупорядочил структуру директорий проекта для более удобного использования в дальнейшем.
6. Создал свой **Docker-образ** **Prometheus** с конфигурацией для мониторинга микросервисов приложения: для этого создал **Dockerfile** и конфигурационный файл **prometheus.yml**, после чего собрал образ.
7. Выполнил сборку образов микросервисов приложения при помощи скрипта:
`for i in ui post-py comment; do cd src/$i; bash docker_build.sh; cd -; done`
8. Определил в **docker/docker-compose.yml** новый сервис - **prometheus**.
9. Поднял сервисы, определенные в **docker/docker-compose.yml**, командой:
`docker-compose up -d`

### 2. Мониторинг состояния микросервисов
1. Производил мониторинг состояния микросервисов в **UI**: в качестве эксперимента специально останавливал сервисы (и позже поднимал их) и наблюдал, как изменится их статус, а также статус зависимых сервисов.

### 3. Сбор метрик хоста с использованием экспортера
1. Определил в **docker/docker-compose.yml** новый сервис - **node-exporter**.
2. Добавил информацию о сервисе **node-exporter** (джобу) в конфигурационный файл **prometheus.yml**.
3. Собрал новый **Docker-образ** **Prometheus**.
4. Пересоздал сервисы:
```
docker-compose down
docker-compose up -d
```
5. Получил с метрики информацию об использовании **CPU**, после чего, зайдя на **docker-хост** с приложением, добавил нагрузку командой **yes > /dev/null**, чтобы понаблюдать, как на это отреагирует система мониторинга.
6. Запушил собранные мной образы приложения и **Prometheus** в свой **DockerHub**:
```
docker push jaxowner/ui
docker push jaxowner/comment
docker push jaxowner/post
docker push jaxowner/prometheus
```
</details>

---
# HOMEWORK #18:

<details>
  <summary>Описание</summary>

### 1. Подготовил окружение.
### 2. Настроил логирование Docker-контейнеров.
### 3. Настроил сбор неструктурированных логов.
### 4. Настроил визуализацию логов.
### 5. Настроил сбор структурированных логов.
### 6. Настроил распределенный трейсинг.
</details>

---
# HOMEWORK #19:

<details>
  <summary>Описание</summary>

### 1. Опиcал приложение в контексте Kubernetes с помощью manifest- ов в YAML-формате. Основным примитивом был Deployment.
Создал следующие файлы с **Deployment**-манифестами:
- **post-deployment.yml**
- **ui-deployment.yml**
- **comment-deployment.yml**
- **mongo-deployment.yml**
### 2. Установил k8s на двух нодах с требуемыми по заданию характеристиками.
1. Использовал документацию **kubeadm** https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/
2. Также развернул **k8s** в **Yandex Cloud** с помощью предоставляемого **Managed Service for Kubernetes**.
3. Потренировался в скейлинге количества нод в группе узлов.
### 3. Применил созданные ранее манифесты одной командой:
`kubectl apply -f ./kubernetes/reddit/`
### 4. Проверил, что поды успешно запустились, посомтрев их статус и прочую информацию о них командой:
`kubectl get pod --all-namespaces`

</details>

---
# HOMEWORK #20:

<details>
  <summary>Описание</summary>

### 1. Развернул локальное окружение для работы с Kubernetes.
1. **kubectl** уже был установлен мной в прошлом ДЗ. Версия - 1.25.2.
2. Установил локально **Minikube** версии 1.27.1 и развернул **Minikube**-кластер.
3. В директории **./kubernetes/reddit** описал следующие манифесты:
- comment-deployment.yml
- comment-mongodb-service.yml
- comment-service.yml
- dev-namespace.yml
- mongodb-service.yml
- mongo-deployment.yml
- post-deployment.yml
- post-mongodb-service.yml
- post-service.yml
- ui-deployment.yml
- ui-service.yml
4. Установил тип **NodePort** для сервиса **ui**.
5. Потрренировался в скейлинге подов, пробросе портов, переключении **namespace**'ов.
6. Изучил **addon**'ы - в частности, "потрогал" стандартный **minikube dashboard**.
.. и т.д.
### 2. Развернул Kubernetes в Yandex Cloud.
1. Аналогично прошлому ДЗ развернул **k8s** в **Yandex Cloud** с помощью предоставляемого **Managed Service for Kubernetes**, создав при этом группу из двух нод (узлов).
2. Переключился с контекста кластера **Minikube**'а на контекст созданного кластера в **Yandex Cloud**.
3. Создал **dev** namespace.
### 3. Запустил приложение reddit в Kubernetes.
1. Задеплоил все компоненты приложения **reddit**в namespace **dev** в кластере **Yandex Cloud**:
`kubectl apply -f . -n dev`
2. Убедился в работоспособности приложения.
3. К **pull request**'у приложил скриншоты из консоли **Yandex Cloud**, а также скриншоты работающего приложения.
</details>

---
